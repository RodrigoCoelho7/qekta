ray_local_mode: False                 # set to true for debugging
num_cpus:       24                    # number of cpus to use
num_gpus:       0                     # number of gpus to use
method:         QuantumKernels        # name of method: use default one
ray_logging_path: logs/make_class     # path for logging (deprecated)
ray_num_trial_samples:  10            # number of samples with different seeds per hyperparameter configuration
type:                   train         # type (use train)
num_cpus_worker:        2             # number of cpus per worker

algorithm_config:
  dataset:          checkerboard      # dataset to use: checkerboard,corners,donuts,spirals
  num_samples:      30                # number of training datapoints (different datasets have specific numbers of training datapoints)
  num_features:     2                 # number of features: all above datasets are 2D (2 features)
  feature_scaling:  none              # whether to scale features to a specific range or not: pi/2, pi, none
  full_kta:         False             # whether to just calculate KTA for entire training dataset or use subsampling technique
  cost_function:    trace_kta         # cost function to use: alle xperiments used trace_kta
  subsample_size:   8                 # subsample size for the subsample kta technique (only matters if full_kta=False)
  lr:               0.1               # lr of quantum circuit parameters
  num_epochs:       1000              # Number of epochs
  num_layers:       5                 # Quantum circuit layers
  num_qubits_equal_num_features:  False   # whether to use cycle encoding so that number of qubits = number of features
  num_batches_per_epoch: 1                # number of batches to sample per epoch (deprecated, always 1)
  use_importance_sampling:  False         # deprecated
  ansatz:           paper                 # quantum ansatz to use
  num_qubits:       4                     # number of qubits to use (only matters if num_qubits_equal_num_features=False)
  use_input_scaling:  True                # use input scaling or not
  use_data_reuploading: True              # use data reuploading or not
  use_nystrom_training:   False           # use nystrom approximation during training besides just generating final kernel matrix
  use_nystrom_approx:     False           # use nystrom approx to generate final kernel matrix
  num_landmarks:          4               # number of landmarks to use if nystrom_approx is used
  validate_every_epoch:   25              # validate and calculate metrics for entire dataset every x epochs

  use_shots:    False                     # use shots or calculate
  n_shots:      100                       # if use_shots, number of shots

  use_coherent_noise:     True            # use coherent noise or not
  std:                    #0              # delta to use for coherent nosie
    - grid_search
    - float
    - [0.1,0.2,0.5]

  use_depolarizing_noise:     False       # use depolarizing noise or not
  depolarizing_strength:      0.01        # depolarizing strength to use

  
  # 1440 * 3 runs


